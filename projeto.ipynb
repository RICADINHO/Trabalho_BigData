{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml import Pipeline\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"ProjetoABD\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dados = spark.read.load('avioes/raw',format='csv',sep=',',inferSchema=True, header=True)\n",
    "\n",
    "dados = spark.read.load('/home/jovyan/code/raw',format='csv',sep=',',inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.printSchema()\n",
    "dados.show()\n",
    "dados.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Removing duplicates if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dados: number of rows: {dados.count()}, after dropduplicates: {dados.dropDuplicates().count() }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Removing useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_dismiss = [\n",
    "    # Informações duplicadas ou derivadas\n",
    "    'DepDelayMinutes', 'DepDel15', 'DepartureDelayGroups',\n",
    "    'ArrDelayMinutes', 'ArrDel15', 'ArrivalDelayGroups',\n",
    "    'DepTimeBlk','ArrTimeBlk','DestAirportID','DestAirportSeqID',\n",
    "    'DestCityMarketID','OriginAirportID','OriginAirportSeqID',\n",
    "    'OriginCityMarketID','Marketing_Airline_Network',\n",
    "    'Operating_Airline','Flight_Number_Marketing_Airline',\n",
    "    'FlightDate','OriginWac','DestWac','Flights',\n",
    "    'Duplicate',\"OriginStateFips\",\"DestStateFips\",'OriginState',\n",
    "    \"DestState\",\n",
    "\n",
    "    # Diverted flights – detalhes específicos desnecessários\n",
    "    'DivAirportLandings', 'DivReachedDest', 'DivActualElapsedTime',\n",
    "    'DivArrDelay', 'DivDistance',\n",
    "\n",
    "    # Todas as colunas relacionadas com aeroportos desviados \n",
    "    'Div1Airport', 'Div1AirportID', 'Div1AirportSeqID', 'Div1WheelsOn',\n",
    "    'Div1TotalGTime', 'Div1LongestGTime', 'Div1WheelsOff', 'Div1TailNum',\n",
    "    'Div2Airport', 'Div2AirportID', 'Div2AirportSeqID', 'Div2WheelsOn',\n",
    "    'Div2TotalGTime', 'Div2LongestGTime', 'Div2WheelsOff', 'Div2TailNum',\n",
    "    'Div3Airport', 'Div3AirportID', 'Div3AirportSeqID', 'Div3WheelsOn',\n",
    "    'Div3TotalGTime', 'Div3LongestGTime', 'Div3WheelsOff', 'Div3TailNum',\n",
    "    'Div4Airport', 'Div4AirportID', 'Div4AirportSeqID', 'Div4WheelsOn',\n",
    "    'Div4TotalGTime', 'Div4LongestGTime', 'Div4WheelsOff', 'Div4TailNum',\n",
    "    'Div5Airport', 'Div5AirportID', 'Div5AirportSeqID', 'Div5WheelsOn',\n",
    "    'Div5TotalGTime', 'Div5LongestGTime', 'Div5WheelsOff', 'Div5TailNum',\n",
    "\n",
    "    # Identificadores redundantes\n",
    "    'DOT_ID_Marketing_Airline', 'DOT_ID_Operating_Airline','DayofMonth',\n",
    "    'IATA_Code_Marketing_Airline', 'IATA_Code_Operating_Airline','Tail_Number',\n",
    "\n",
    "    #dados com mts nulls\n",
    "    'CancellationCode','Originally_Scheduled_Code_Share_Airline','DOT_ID_Originally_Scheduled_Code_Share_Airline',\n",
    "    'IATA_Code_Originally_Scheduled_Code_Share_Airline','Flight_Num_Originally_Scheduled_Code_Share_Airline','CarrierDelay',\n",
    "    'WeatherDelay','NASDelay','SecurityDelay','FirstDepTime','TotalAddGTime','LongestAddGTime','_c119','LateAircraftDelay'\n",
    "]\n",
    "\n",
    "dados = dados.drop(*cols_to_dismiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.printSchema()\n",
    "dados.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter hhmm para minutos\n",
    "def hhmm_to_minutes(col):\n",
    "    return (F.floor(col / 100) * 60) + (col % 100)\n",
    "\n",
    "# Tempos de partida\n",
    "dados = dados.withColumn(\"DepTime\", hhmm_to_minutes(F.col(\"DepTime\")))\n",
    "dados = dados.withColumn(\"CRSDepTime\", hhmm_to_minutes(F.col(\"CRSDepTime\")))\n",
    "dados = dados.withColumn(\"DepDelay\",F.col(\"DepTime\") - F.col(\"CRSDepTime\"))\n",
    "\n",
    "# Tempos de chegada\n",
    "dados = dados.withColumn(\"ArrTime\", hhmm_to_minutes(F.col(\"ArrTime\")))\n",
    "dados = dados.withColumn(\"CRSArrTime\", hhmm_to_minutes(F.col(\"CRSArrTime\")))\n",
    "dados = dados.withColumn(\"ArrDelay\", F.col(\"ArrTime\") - F.col(\"CRSArrTime\"))\n",
    "# F.greatest(F.col(\"ArrTime\") - F.col(\"CRSArrTime\"), F.lit(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meter a localizaçao da partida e destino numa só tabela\n",
    "dados = dados.withColumn('OriginCityNameState',\n",
    "                          F.concat_ws(\n",
    "                              ',',\n",
    "                                F.split(F.col('OriginCityName'),',')[0],\n",
    "                                F.col(\"OriginStateName\")\n",
    "    ))\n",
    "\n",
    "dados = dados.withColumn('DestCityNameState',\n",
    "                          F.concat_ws(\n",
    "                              ',',\n",
    "                                F.split(F.col('DestCityName'),',')[0],\n",
    "                                F.col(\"DestStateName\")\n",
    "    ))\n",
    "\n",
    "cols_to_dismiss = [\"OriginCityName\",\"OriginStateName\",\"DestCityName\",\"DestStateName\"]\n",
    "dados = dados.drop(*cols_to_dismiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados.withColumnRenamed(\"Operating_Airline \",\"Operating_Airline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.printSchema()\n",
    "dados.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver em que colunas estão os nulos (by columns)\n",
    "nulls = {col: dados.filter(dados[col].isNull()).count() for col in dados.columns}\n",
    "nulls\n",
    "\n",
    "# valores corridos ao dataset todo sem fazer nada aos nulls\n",
    "'''\n",
    "{'Year': 0,\n",
    " 'Quarter': 0,\n",
    " 'Month': 0,\n",
    " 'DayOfWeek': 0,\n",
    " 'Operated_or_Branded_Code_Share_Partners': 0,\n",
    " 'Operating_Airline ': 0,\n",
    " 'Flight_Number_Operating_Airline': 0,\n",
    " 'Origin': 0,\n",
    " 'Dest': 0,\n",
    " 'CRSDepTime': 0,\n",
    " 'DepTime': 761652,\n",
    " 'DepDelay': 761652,\n",
    " 'TaxiOut': 780561,\n",
    " 'WheelsOff': 780551,\n",
    " 'WheelsOn': 793133,\n",
    " 'TaxiIn': 793143,\n",
    " 'CRSArrTime': 0,\n",
    " 'ArrTime': 786177,\n",
    " 'ArrDelay': 786177,\n",
    " 'Cancelled': 0,\n",
    " 'Diverted': 0,\n",
    " 'CRSElapsedTime': 22,\n",
    " 'ActualElapsedTime': 845637,\n",
    " 'AirTime': 852561,\n",
    " 'Distance': 0,\n",
    " 'DistanceGroup': 0,\n",
    " 'OriginCityNameState': 0,\n",
    " 'DestCityNameState': 0}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remover nulls\n",
    "dados = dados.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Quarter: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- Operated_or_Branded_Code_Share_Partners: string (nullable = true)\n",
      " |-- Operating_Airline: string (nullable = true)\n",
      " |-- Flight_Number_Operating_Airline: integer (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- CRSDepTime: long (nullable = true)\n",
      " |-- DepTime: long (nullable = true)\n",
      " |-- DepDelay: long (nullable = true)\n",
      " |-- TaxiOut: double (nullable = true)\n",
      " |-- WheelsOff: integer (nullable = true)\n",
      " |-- WheelsOn: integer (nullable = true)\n",
      " |-- TaxiIn: double (nullable = true)\n",
      " |-- CRSArrTime: long (nullable = true)\n",
      " |-- ArrTime: long (nullable = true)\n",
      " |-- ArrDelay: long (nullable = true)\n",
      " |-- Cancelled: double (nullable = true)\n",
      " |-- Diverted: double (nullable = true)\n",
      " |-- CRSElapsedTime: double (nullable = true)\n",
      " |-- ActualElapsedTime: double (nullable = true)\n",
      " |-- AirTime: double (nullable = true)\n",
      " |-- Distance: double (nullable = true)\n",
      " |-- DistanceGroup: integer (nullable = true)\n",
      " |-- OriginCityNameState: string (nullable = false)\n",
      " |-- DestCityNameState: string (nullable = false)\n",
      "\n",
      "+----+-------+-----+---------+---------------------------------------+-----------------+-------------------------------+------+----+----------+-------+--------+-------+---------+--------+------+----------+-------+--------+---------+--------+--------------+-----------------+-------+--------+-------------+--------------------+--------------------+\n",
      "|Year|Quarter|Month|DayOfWeek|Operated_or_Branded_Code_Share_Partners|Operating_Airline|Flight_Number_Operating_Airline|Origin|Dest|CRSDepTime|DepTime|DepDelay|TaxiOut|WheelsOff|WheelsOn|TaxiIn|CRSArrTime|ArrTime|ArrDelay|Cancelled|Diverted|CRSElapsedTime|ActualElapsedTime|AirTime|Distance|DistanceGroup| OriginCityNameState|   DestCityNameState|\n",
      "+----+-------+-----+---------+---------------------------------------+-----------------+-------------------------------+------+----+----------+-------+--------+-------+---------+--------+------+----------+-------+--------+---------+--------+--------------+-----------------+-------+--------+-------------+--------------------+--------------------+\n",
      "|2020|      4|   10|        4|                           UA_CODESHARE|               YV|                           6023|   CLT| IAD|       885|    884|      -1|   53.0|     1537|    1632|   8.0|       981|   1000|      19|      0.0|     0.0|          96.0|            116.0|   55.0|   322.0|            2|Charlotte,North C...| Washington,Virginia|\n",
      "|2020|      4|   10|        5|                           UA_CODESHARE|               YV|                           6112|   PIT| IAH|       975|    971|      -4|    8.0|     1619|    1836|   8.0|      1108|   1124|      16|      0.0|     0.0|         193.0|            213.0|  197.0|  1117.0|            5|Pittsburgh,Pennsy...|       Houston,Texas|\n",
      "|2020|      4|   10|        2|                           UA_CODESHARE|               YV|                           6123|   SDF| IAH|       420|    420|       0|   29.0|      729|     857|   5.0|       510|    542|      32|      0.0|     0.0|         150.0|            182.0|  148.0|   788.0|            4| Louisville,Kentucky|       Houston,Texas|\n",
      "|2020|      4|   10|        2|                           UA_CODESHARE|               YV|                           6130|   LIT| IAH|       430|    429|      -1|   59.0|      808|     910|   8.0|       529|    558|      29|      0.0|     0.0|          99.0|            129.0|   62.0|   374.0|            2|Little Rock,Arkansas|       Houston,Texas|\n",
      "|2020|      4|   10|        6|                           UA_CODESHARE|               YV|                           6135|   IAD| SRQ|       630|    713|      83|   10.0|     1203|    1407|   2.0|       779|    849|      70|      0.0|     0.0|         149.0|            136.0|  124.0|   849.0|            4| Washington,Virginia|Sarasota/Bradento...|\n",
      "|2020|      4|   10|        6|                           UA_CODESHARE|               YV|                           6135|   SRQ| IAD|       815|    905|      90|   13.0|     1518|    1707|   6.0|       956|   1033|      77|      0.0|     0.0|         141.0|            128.0|  109.0|   849.0|            4|Sarasota/Bradento...| Washington,Virginia|\n",
      "|2020|      4|   10|        1|                           UA_CODESHARE|               YV|                           6105|   IAH| DFW|       590|    589|      -1|   58.0|     1047|    1124|  11.0|       669|    695|      26|      0.0|     0.0|          79.0|            106.0|   37.0|   224.0|            1|       Houston,Texas|Dallas/Fort Worth...|\n",
      "|2020|      4|   10|        1|                           UA_CODESHARE|               YV|                           6113|   DTW| IAD|       900|    890|     -10|   27.0|     1517|    1639|   6.0|       989|   1005|      16|      0.0|     0.0|          89.0|            115.0|   82.0|   383.0|            2|    Detroit,Michigan| Washington,Virginia|\n",
      "|2020|      4|   10|        5|                           UA_CODESHARE|               YV|                           6071|   CHS| IAH|      1020|   1014|      -6|   15.0|     1709|    1910|   9.0|      1123|   1159|      36|      0.0|     0.0|         163.0|            205.0|  181.0|   925.0|            4|Charleston,South ...|       Houston,Texas|\n",
      "|2020|      4|   10|        6|                           UA_CODESHARE|               YV|                           6119|   IAD| JAX|      1050|   1109|      59|   15.0|     1844|    2024|   3.0|      1177|   1227|      50|      0.0|     0.0|         127.0|            118.0|  100.0|   630.0|            3| Washington,Virginia|Jacksonville,Florida|\n",
      "|2020|      4|   10|        4|                           UA_CODESHARE|               YV|                           6051|   BNA| IAH|       660|    697|      37|   15.0|     1152|    1333|   5.0|       798|    818|      20|      0.0|     0.0|         138.0|            121.0|  101.0|   657.0|            3| Nashville,Tennessee|       Houston,Texas|\n",
      "|2020|      4|   10|        2|                           UA_CODESHARE|               YV|                           6135|   SRQ| IAD|       815|   1332|     517|   11.0|     2223|       3|  10.0|       956|     13|    -943|      0.0|     0.0|         141.0|            121.0|  100.0|   849.0|            4|Sarasota/Bradento...| Washington,Virginia|\n",
      "|2020|      4|   10|        2|                           UA_CODESHARE|               YV|                           6146|   MCI| IAH|       390|    387|      -3|   11.0|      638|     855|  14.0|       520|    549|      29|      0.0|     0.0|         130.0|            162.0|  137.0|   643.0|            3|Kansas City,Missouri|       Houston,Texas|\n",
      "|2020|      4|   10|        2|                           UA_CODESHARE|               YV|                           6148|   IND| IAH|       420|    418|      -2|   13.0|      711|     849|  18.0|       511|    547|      36|      0.0|     0.0|         151.0|            189.0|  158.0|   844.0|            4|Indianapolis,Indiana|       Houston,Texas|\n",
      "|2020|      4|   10|        4|                           UA_CODESHARE|               YV|                           6105|   IAH| DFW|       590|    587|      -3|   59.0|     1046|    1128|  15.0|       669|    703|      34|      0.0|     0.0|          79.0|            116.0|   42.0|   224.0|            1|       Houston,Texas|Dallas/Fort Worth...|\n",
      "|2020|      4|   10|        1|                           UA_CODESHARE|               YV|                           6121|   CLE| IAD|       915|    911|      -4|   21.0|     1532|    1643|   6.0|       993|   1009|      16|      0.0|     0.0|          78.0|             98.0|   71.0|   288.0|            2|      Cleveland,Ohio| Washington,Virginia|\n",
      "|2020|      4|   10|        5|                           UA_CODESHARE|               YV|                           6021|   CMH| IAH|       390|    385|      -5|    8.0|      633|     830|  16.0|       507|    526|      19|      0.0|     0.0|         177.0|            201.0|  177.0|   986.0|            4|       Columbus,Ohio|       Houston,Texas|\n",
      "|2020|      4|   10|        6|                           UA_CODESHARE|               YV|                           6126|   IAH| JAX|       905|    904|      -1|   16.0|     1520|    1837|   6.0|      1103|   1123|      20|      0.0|     0.0|         138.0|            159.0|  137.0|   817.0|            4|       Houston,Texas|Jacksonville,Florida|\n",
      "|2020|      4|   10|        5|                           UA_CODESHARE|               YV|                           6132|   IAH| XNA|       880|    897|      17|   68.0|     1605|    1714|   7.0|       977|   1041|      64|      0.0|     0.0|          97.0|            144.0|   69.0|   438.0|            2|       Houston,Texas|Fayetteville,Arka...|\n",
      "|2020|      4|   10|        1|                           UA_CODESHARE|               YV|                           6152|   SAV| IAD|       900|    897|      -3|   25.0|     1522|    1651|   5.0|      1001|   1016|      15|      0.0|     0.0|         101.0|            119.0|   89.0|   515.0|            3|    Savannah,Georgia| Washington,Virginia|\n",
      "+----+-------+-----+---------+---------------------------------------+-----------------+-------------------------------+------+----+----------+-------+--------+-------+---------+--------+------+----------+-------+--------+---------+--------+--------------+-----------------+-------+--------+-------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28341220"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.printSchema()\n",
    "dados.show()\n",
    "dados.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colunas numericas\n",
    "input_cols_num = [\n",
    "    \"Year\",\n",
    "    \"Quarter\",\n",
    "    \"Month\",\n",
    "    \"DayOfWeek\",\n",
    "    \"Flight_Number_Operating_Airline\",\n",
    "    \"CRSDepTime\",\n",
    "    \"DepTime\",\n",
    "    \"DepDelay\",\n",
    "    \"TaxiOut\",\n",
    "    \"WheelsOff\",\n",
    "    \"Distance\",\n",
    "    \"DistanceGroup\",\n",
    "    \"AirTime\",\n",
    "    \"CRSArrTime\",\n",
    "    \"ArrTime\",\n",
    "    \"ArrDelay\",\n",
    "    \"WheelsOn\",\n",
    "    \"TaxiIn\",\n",
    "    \"Cancelled\",\n",
    "    \"Diverted\",\n",
    "    \"CRSElapsedTime\",\n",
    "    \"ActualElapsedTime\"\n",
    "]\n",
    "\n",
    "\n",
    "# colunas categoricas\n",
    "input_cols_str = [\n",
    "    \"Operated_or_Branded_Code_Share_Partners\",\n",
    "    \"Operating_Airline\",\n",
    "    \"Origin\",\n",
    "    \"Dest\",\n",
    "    \"OriginCityNameState\",\n",
    "    \"DestCityNameState\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=input_cols_num, outputCol=\"numeric_features\")\n",
    "numeric_df = assembler.transform(dados).select(\"numeric_features\")\n",
    "\n",
    "correlation_matrix = Correlation.corr(numeric_df, \"numeric_features\", \"pearson\").head()[0].toArray()\n",
    "\n",
    "corr_df = pd.DataFrame(correlation_matrix, columns=input_cols_num, index=input_cols_num)\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(corr_df, annot=True, cmap=\"coolwarm\", fmt=\".2f\", square=True)\n",
    "plt.title(\"Matriz de correlação das features numericas\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cenas do dia da semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = dados.limit(1000000)\n",
    "df = df_small.toPandas()\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, x='DayOfWeek', y='ArrDelay')\n",
    "plt.title('Atraso na Chegada por Dia da Semana')\n",
    "plt.show()\n",
    "\n",
    "df_filtrado = df[df['ArrDelay'] > 15]\n",
    "contagem = df_filtrado.groupby('DayOfWeek').size().reset_index(name='QtdAtrasos')\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=contagem, x='DayOfWeek', y='QtdAtrasos', palette='Blues_d')\n",
    "plt.title('Voos com Atraso na Chegada > 15 min por Dia da Semana')\n",
    "plt.xlabel('Dia da Semana')\n",
    "plt.ylabel('Quantidade de Voos')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, x='DayOfWeek', y='DepDelay')\n",
    "plt.title('Atraso na Partida por Dia da Semana')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "df_filtrado = df[df['DepDelay'] > 15]\n",
    "contagem = df_filtrado.groupby('DayOfWeek').size().reset_index(name='QtdAtrasos')\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=contagem, x='DayOfWeek', y='QtdAtrasos', palette='Blues_d')\n",
    "plt.title('Voos com Atraso na partida > 15 min por Dia da Semana')\n",
    "plt.xlabel('Dia da Semana')\n",
    "plt.ylabel('Quantidade de Voos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode das colunas categoricas\n",
    "available_cols = set(dados.columns)\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_Index\", handleInvalid='keep')\n",
    "            for col in input_cols_str if col in available_cols]\n",
    "\n",
    "# juntar as colunas\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "    \"Year\",\"Quarter\",\"Month\",\"DayOfWeek\",\"Flight_Number_Operating_Airline\",\"CRSDepTime\",\"DepTime\",\"TaxiOut\",\n",
    "    \"WheelsOff\",\"Distance\",\"DistanceGroup\",\"AirTime\",\"CRSArrTime\",\"ArrTime\",\"WheelsOn\",\"TaxiIn\",\"Cancelled\",\n",
    "    \"Diverted\",\"CRSElapsedTime\",\"ActualElapsedTime\",\"Origin_Index\", \"Dest_Index\",\"Operating_Airline_Index\",\n",
    "    \"Operated_or_Branded_Code_Share_Partners_Index\", \"OriginCityNameState_Index\",\"DestCityNameState_Index\"\n",
    "    ],\n",
    "    outputCol=\"features_unscaled\"\n",
    ")\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features_unscaled\", outputCol=\"features\", withStd=True, withMean=True)\n",
    "kmeans = KMeans(k=5, seed=1, featuresCol=\"features\", predictionCol=\"cluster\")\n",
    "pipeline = Pipeline(stages=indexers + [assembler, scaler, kmeans])\n",
    "\n",
    "# correr o modelo\n",
    "model = pipeline.fit(dados)\n",
    "clustered_df = model.transform(dados)\n",
    "\n",
    "print(\"KMeans feito\")\n",
    "\n",
    "# Ver a média do delay\n",
    "clustered_df.groupBy(\"cluster\").agg(\n",
    "    {\"DepDelay\": \"avg\", \"ArrDelay\": \"avg\"}\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "delay_summary = clustered_df.groupBy(\"cluster\").agg(\n",
    "    {\"DepDelay\": \"avg\", \"ArrDelay\": \"avg\"}\n",
    ").toPandas()\n",
    "\n",
    "x = delay_summary[\"cluster\"]\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, delay_summary[\"avg(DepDelay)\"], width, label=\"Avg DepDelay\", color='skyblue')\n",
    "ax.bar(x + width/2, delay_summary[\"avg(ArrDelay)\"], width, label=\"Avg ArrDelay\", color='salmon')\n",
    "\n",
    "ax.set_xlabel(\"Cluster\")\n",
    "ax.set_ylabel(\"Delay (minutos)\")\n",
    "ax.set_title(\"Média do ArrDelay e DepDelay por cluster\")\n",
    "ax.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features dos clusters mais os clusters\n",
    "cols_to_collect = [\n",
    "    \"Year\",\"Quarter\",\"Month\",\"DayOfWeek\",\"Flight_Number_Operating_Airline\",\"CRSDepTime\",\n",
    "    \"DepTime\",\"TaxiOut\",\"WheelsOff\",\"Distance\",\"DistanceGroup\",\"AirTime\",\"CRSArrTime\",\n",
    "    \"ArrTime\",\"WheelsOn\",\"TaxiIn\",\"Cancelled\",\"Diverted\",\"CRSElapsedTime\",\"ActualElapsedTime\",\n",
    "    \"Origin_Index\",\"Dest_Index\",\"Operating_Airline_Index\",\"Operated_or_Branded_Code_Share_Partners_Index\",\n",
    "    \"OriginCityNameState_Index\",\"DestCityNameState_Index\",\"cluster\"\n",
    "]\n",
    "\n",
    "sampled = clustered_df.select(*cols_to_collect).sample(fraction=0.05, seed=42)\n",
    "pdf = sampled.toPandas()\n",
    "\n",
    "global_mean = pdf.drop(columns=[\"cluster\"]).mean()\n",
    "cluster_means = pdf.groupby(\"cluster\").mean()\n",
    "\n",
    "differences = cluster_means - global_mean\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(differences.T, cmap=\"coolwarm\", center=0, annot=True, fmt=\".2f\")\n",
    "plt.title(\"Diferenças das médias das features por cluster\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevância das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\n",
    "    #\"Operated_or_Branded_Code_Share_Partners\",\n",
    "    \"Operating_Airline\",\n",
    "    \"Origin\",\n",
    "    \"Dest\",\n",
    "    #\"OriginCityNameState\",\n",
    "    #\"DestCityNameState\"\n",
    "]\n",
    "\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=c + \"_Index\", handleInvalid=\"keep\") \n",
    "            for c in categorical_cols]\n",
    "\n",
    "\n",
    "all_features = [\n",
    "    \"CRSDepTime\", \"DepTime\", \"TaxiOut\", \"WheelsOff\", \"WheelsOn\", \"TaxiIn\",\n",
    "    \"CRSArrTime\", \"ArrTime\", \"AirTime\", \"Distance\", \"CRSElapsedTime\", \"ActualElapsedTime\",\n",
    "    \"Year\",\"Quarter\",\"Month\", \"DayOfWeek\"\n",
    "] + [c + \"_Index\" for c in categorical_cols]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=all_features, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"DepDelay\", numTrees=40, seed=42,maxBins=400)\n",
    "pipeline = Pipeline(stages=indexers + [assembler, rf])\n",
    "\n",
    "rf_model = pipeline.fit(dados)\n",
    "importances = rf_model.stages[-1].featureImportances.toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = all_features\n",
    "importance_series = pd.Series(importances, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=importance_series.values, y=importance_series.index, palette=\"magma\")\n",
    "plt.title(\"Importancia dos features no DepDelay\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"ArrDelay\", numTrees=40, seed=42,maxBins=400)\n",
    "pipeline = Pipeline(stages=indexers + [assembler, rf])\n",
    "\n",
    "rf_model = pipeline.fit(dados)\n",
    "importances = rf_model.stages[-1].featureImportances.toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = all_features\n",
    "importance_series = pd.Series(importances, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=importance_series.values, y=importance_series.index, palette=\"magma\")\n",
    "plt.title(\"Importancia dos features no ArrDelay\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Modelagem Bruno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_limitados=dados.limit(10000000)\n",
    "#dados_limitados.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_limitados = ( dados_limitados\n",
    "            .withColumn(\"Delay\", \n",
    "                                F.when((F.col(\"ArrDelay\") > 15), 1).otherwise(0))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----+---------+-----------------+-------------------------------+------+----+----------+-------+-------+---------+----------+---------+--------+--------------+-----------------+-------+--------+-------------+--------------------+--------------------+-----+\n",
      "|Year|Quarter|Month|DayOfWeek|Operating_Airline|Flight_Number_Operating_Airline|Origin|Dest|CRSDepTime|DepTime|TaxiOut|WheelsOff|CRSArrTime|Cancelled|Diverted|CRSElapsedTime|ActualElapsedTime|AirTime|Distance|DistanceGroup| OriginCityNameState|   DestCityNameState|Delay|\n",
      "+----+-------+-----+---------+-----------------+-------------------------------+------+----+----------+-------+-------+---------+----------+---------+--------+--------------+-----------------+-------+--------+-------------+--------------------+--------------------+-----+\n",
      "|2020|      4|   10|        4|               YV|                           6023|   CLT| IAD|       885|    884|   53.0|     1537|       981|      0.0|     0.0|          96.0|            116.0|   55.0|   322.0|            2|Charlotte,North C...| Washington,Virginia|    1|\n",
      "|2020|      4|   10|        5|               YV|                           6112|   PIT| IAH|       975|    971|    8.0|     1619|      1108|      0.0|     0.0|         193.0|            213.0|  197.0|  1117.0|            5|Pittsburgh,Pennsy...|       Houston,Texas|    1|\n",
      "|2020|      4|   10|        2|               YV|                           6123|   SDF| IAH|       420|    420|   29.0|      729|       510|      0.0|     0.0|         150.0|            182.0|  148.0|   788.0|            4| Louisville,Kentucky|       Houston,Texas|    1|\n",
      "|2020|      4|   10|        2|               YV|                           6130|   LIT| IAH|       430|    429|   59.0|      808|       529|      0.0|     0.0|          99.0|            129.0|   62.0|   374.0|            2|Little Rock,Arkansas|       Houston,Texas|    1|\n",
      "|2020|      4|   10|        6|               YV|                           6135|   IAD| SRQ|       630|    713|   10.0|     1203|       779|      0.0|     0.0|         149.0|            136.0|  124.0|   849.0|            4| Washington,Virginia|Sarasota/Bradento...|    1|\n",
      "|2020|      4|   10|        6|               YV|                           6135|   SRQ| IAD|       815|    905|   13.0|     1518|       956|      0.0|     0.0|         141.0|            128.0|  109.0|   849.0|            4|Sarasota/Bradento...| Washington,Virginia|    1|\n",
      "|2020|      4|   10|        1|               YV|                           6105|   IAH| DFW|       590|    589|   58.0|     1047|       669|      0.0|     0.0|          79.0|            106.0|   37.0|   224.0|            1|       Houston,Texas|Dallas/Fort Worth...|    1|\n",
      "|2020|      4|   10|        1|               YV|                           6113|   DTW| IAD|       900|    890|   27.0|     1517|       989|      0.0|     0.0|          89.0|            115.0|   82.0|   383.0|            2|    Detroit,Michigan| Washington,Virginia|    1|\n",
      "|2020|      4|   10|        5|               YV|                           6071|   CHS| IAH|      1020|   1014|   15.0|     1709|      1123|      0.0|     0.0|         163.0|            205.0|  181.0|   925.0|            4|Charleston,South ...|       Houston,Texas|    1|\n",
      "|2020|      4|   10|        6|               YV|                           6119|   IAD| JAX|      1050|   1109|   15.0|     1844|      1177|      0.0|     0.0|         127.0|            118.0|  100.0|   630.0|            3| Washington,Virginia|Jacksonville,Florida|    1|\n",
      "+----+-------+-----+---------+-----------------+-------------------------------+------+----+----------+-------+-------+---------+----------+---------+--------+--------------+-----------------+-------+--------+-------------+--------------------+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dados_limitados = dados_limitados.drop('Operated_or_Branded_Code_Share_Partners','DepDelay','ArrDelay'\n",
    "                                       ,'ArrTime' ,'TaxiIn','WheelsOn')\n",
    "dados_limitados.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns: ['Operating_Airline', 'Origin', 'Dest', 'OriginCityNameState', 'DestCityNameState']\n",
      "Numeric columns: ['Year', 'Quarter', 'Month', 'DayOfWeek', 'Flight_Number_Operating_Airline', 'CRSDepTime', 'DepTime', 'TaxiOut', 'WheelsOff', 'CRSArrTime', 'Cancelled', 'Diverted', 'CRSElapsedTime', 'ActualElapsedTime', 'AirTime', 'Distance', 'DistanceGroup', 'Delay']\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.types as T\n",
    "\n",
    "# The columns at stake\n",
    "cols_non_numeric = [field.name for field in dados_limitados.schema.fields if isinstance(\n",
    "    field.dataType, T.TimestampType) or isinstance(field.dataType, T.StringType)]\n",
    "cols_numeric = [col for col in dados_limitados.columns if col not in cols_non_numeric]\n",
    "\n",
    "# Recall columns at stake\n",
    "print(f'Non-numeric columns: {cols_non_numeric}')\n",
    "print(f'Numeric columns: {cols_numeric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set which columns not to be used as features. \n",
    "cols_not_features = ['Delay']\n",
    "\n",
    "# Set columns to be used by StringIndexer() and OneHotEncoder()\n",
    "\n",
    "categorical_cols = [i for i in cols_non_numeric if i not in cols_not_features]\n",
    "non_categorical_cols = [i for i in cols_numeric if i not in cols_not_features]\n",
    "index_output_cols = [x + ' Index' for x in categorical_cols]\n",
    "ohe_output_cols = [x + ' OHE' for x in categorical_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features to be used (OHE were categorical):\n",
      " ['Operating_Airline OHE', 'Origin OHE', 'Dest OHE', 'OriginCityNameState OHE', 'DestCityNameState OHE', 'Year', 'Quarter', 'Month', 'DayOfWeek', 'Flight_Number_Operating_Airline', 'CRSDepTime', 'DepTime', 'TaxiOut', 'WheelsOff', 'CRSArrTime', 'Cancelled', 'Diverted', 'CRSElapsedTime', 'ActualElapsedTime', 'AirTime', 'Distance', 'DistanceGroup']\n"
     ]
    }
   ],
   "source": [
    "# Assembling an array with the features to be used by the algorithm,\n",
    "# with the help of StringIndexer(), OneHotEncoder() and vectorAssembler()\n",
    "string_indexer = StringIndexer(inputCols=categorical_cols, outputCols=index_output_cols, handleInvalid=\"skip\")\n",
    "ohe_encoder = OneHotEncoder(inputCols=index_output_cols, outputCols=ohe_output_cols)\n",
    "\n",
    "# Put all input features into a single vector, by using a transformer\n",
    "assembler_inputs = ohe_output_cols + non_categorical_cols\n",
    "vec_assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
    "\n",
    "print(f'Input features to be used (OHE were categorical):\\n {assembler_inputs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation split\n",
    "# Two dataframes for training and validation respectively, with a split size of 70/30 (%)\n",
    "df_train, df_validation = dados_limitados.randomSplit([0.7, 0.3], 42)\n",
    "\n",
    "#print(f'There are {df_train.count()} rows in the training set and {df_validation.count()} rows in the validation set.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the train/validation sets as parquet files \n",
    "# Recall that, because it is a sampling, there is not guarantee of \n",
    "# getting the same data split when using the code in a different computer/time. \n",
    "# And we may want to reproduce or share the experiments.\n",
    "\n",
    "df_train.write.mode('overwrite').parquet(\"trans-train_total\")\n",
    "df_validation.write.mode('overwrite').parquet(\"trans-val_total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we already got the data split, delete df_clean to free memory space\n",
    "del dados_limitados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVC algorithm\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.1, labelCol='Delay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a ML pipeline configuration, holding the sequence of the four stages previously set:\n",
    "# 1. string_indexer\n",
    "# 2. ohe_encoder\n",
    "# 3. vec_assembler (related to assembling features into vector)\n",
    "# 4. lsvc (related to ML estimator)\n",
    "\n",
    "pipeline = Pipeline(stages=[string_indexer,ohe_encoder,vec_assembler,lsvc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in the pipeline for further use, should it be required\n",
    "pipeline.save('pipeline-LinearSVM_total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model by fitting the pipeline to the training data\n",
    "# Notice that the model will be a transformer\n",
    "#\n",
    "# Note: in case there are running problems in your computer, set \n",
    "# a lower number of rows to be used in model training\n",
    "\n",
    "# A\n",
    "model = pipeline.fit(df_train)\n",
    "# B\n",
    "#limit_rows = 100000\n",
    "#model = pipeline.fit(df_train.limit(limit_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for further use, should it be required.\n",
    "model.save('model-LinearSVM_total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " ## 5.\n",
    "Evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions by applying the verification data to the transformer\n",
    "df_predictions = model.transform(df_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric areaUnderROC = 0.722571973652999\n"
     ]
    }
   ],
   "source": [
    "# Compute the evaluation metrics \n",
    "# - areaUnderROC using BinaryClassificationEvaluator\n",
    "# - accuracy, precision, recall, and f1Measure, using MultilabelClassificationEvaluator\n",
    "\n",
    "# Using BinaryClassificationEvaluator\n",
    "# Regardless of using default values or not, it is good practice to\n",
    "# explicitly specify them, at the least the important ones\n",
    "\n",
    "# areaUnderROC relates to sensitivity (TP rate) and specificity (FP rate)\n",
    "\n",
    "# Columns of interest: features, rawPrediction, prediction, Fraud\n",
    "df_predictions_eval = df_predictions.select('features', \n",
    "                    'rawPrediction', 'prediction', 'Delay')\n",
    "\n",
    "binary_evaluator = BinaryClassificationEvaluator(labelCol='Delay',\n",
    "                                                 rawPredictionCol='rawPrediction',\n",
    "                                                 metricName='areaUnderROC')\n",
    "    \n",
    "area_under_ROC = binary_evaluator.evaluate(df_predictions_eval)\n",
    "\n",
    "# Print out result\n",
    "print(f'Metric areaUnderROC = {area_under_ROC}')\n",
    "#df_predictions_eval.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------+\n",
      "|prediction|Delay|  count|\n",
      "+----------+-----+-------+\n",
      "|       0.0|    0|2415752|\n",
      "|       0.0|    1| 581636|\n",
      "|       1.0|    1|     61|\n",
      "|       1.0|    0|     11|\n",
      "+----------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Counting of the kind of predictions made\n",
    "df_confusion_matrix = df_predictions_eval.groupBy('prediction','Delay').count()\n",
    "df_confusion_matrix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 61.0, 'TN': 2415752.0, 'FP': 11.0, 'FN': 581636.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the confusion matrix\n",
    "tp = df_confusion_matrix.filter((F.col('prediction')==1.0) & (F.col('Delay')==1)).first()\n",
    "tn = df_confusion_matrix.filter((F.col('prediction')==0.0) & (F.col('Delay')==0)).first()\n",
    "fp = df_confusion_matrix.filter((F.col('prediction')==1.0) & (F.col('Delay')==0)).first()\n",
    "fn = df_confusion_matrix.filter((F.col('prediction')==0.0) & (F.col('Delay')==1)).first()\n",
    "\n",
    "confmat = {'TP': 0.0, 'TN': 0.0, 'FP': 0.0, 'FN': 0.0}\n",
    "if (tp):\n",
    "    confmat['TP'] = tp['count'] * 1.0\n",
    "if (tn):\n",
    "    confmat['TN'] = tn['count'] * 1.0\n",
    "if (fp):\n",
    "    confmat['FP'] = fp['count'] * 1.0\n",
    "if (fn):\n",
    "    confmat['FN'] = fn['count'] * 1.0\n",
    "\n",
    "confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics based on the confusion matrix:\n",
      " Accuracy = 0.8059533738565319\n",
      " Precision = 0.8472222222222222\n",
      " Recall = 0.00010486559153648721\n",
      " Specifity = 0.9999954465731945\n",
      " F1 score = 0.00020970522664493988\n"
     ]
    }
   ],
   "source": [
    "# Based on the confusion matrix, computed the evaluation matrics:\n",
    "#   accuracy, precision, recall, specifity and F1 score\n",
    "\n",
    "# PS: Check divisons by 0.0\n",
    "accuracy = (confmat['TP'] + confmat['TN']) / (confmat['TP'] + confmat['TN'] + confmat['FP'] + confmat['FN'])\n",
    "precision = confmat['TP'] / (confmat['TP'] + confmat['FP'])\n",
    "recall = confmat['TP'] / (confmat['TP'] + confmat['FN'])\n",
    "specificity = confmat['TN'] / (confmat['TN'] + confmat['FP'])\n",
    "f1score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "\n",
    "print('Evaluation metrics based on the confusion matrix:')\n",
    "print(f' Accuracy = {accuracy}')\n",
    "print(f' Precision = {precision}')\n",
    "print(f' Recall = {recall}')\n",
    "print(f' Specifity = {specificity}')\n",
    "print(f' F1 score = {f1score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_pyspark",
   "language": "python",
   "name": "vscode_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
